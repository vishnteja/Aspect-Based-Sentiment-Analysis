cuda memory allocated: 19044352
n_trainable_params: 3428883, n_nontrainable_params: 1323600
> training arguments:
>>> model_name: gcnn
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.asgd.ASGD'>
>>> initializer: <function xavier_uniform_ at 0x0000015AFB7096A8>
>>> learning_rate: 1
>>> dropout: 0.5
>>> l2reg: 1e-05
>>> num_epoch: 10
>>> batch_size: 32
>>> log_step: 5
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> device: cuda
>>> seed: None
>>> valset_ratio: 0
>>> num_layers: 4
>>> in_channels: 600
>>> out_channels: 4
>>> downbot: 20
>>> kernel_size: 4
>>> glove_path: ./glove/glove.840B.300d.txt
>>> model_class: <class 'models.gated_cnn.Gated_CNN'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_raw_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.1412, acc: 0.3500
loss: 1.0329, acc: 0.5000
loss: 1.0181, acc: 0.5375
loss: 0.9940, acc: 0.5641
loss: 0.9984, acc: 0.5675
loss: 0.9915, acc: 0.5750
loss: 0.9935, acc: 0.5723
loss: 0.9910, acc: 0.5766
loss: 0.9865, acc: 0.5799
loss: 0.9875, acc: 0.5787
loss: 0.9839, acc: 0.5818
loss: 0.9785, acc: 0.5859
loss: 0.9710, acc: 0.5918
loss: 0.9753, acc: 0.5879
loss: 0.9758, acc: 0.5871
loss: 0.9761, acc: 0.5883
loss: 0.9796, acc: 0.5846
loss: 0.9768, acc: 0.5868
loss: 0.9746, acc: 0.5882
loss: 0.9760, acc: 0.5859
loss: 0.9725, acc: 0.5887
loss: 0.9710, acc: 0.5886
> val_acc: 0.6500, val_f1: 0.2626
>> saved: state_dict/gcnn_restaurant_val_acc0.65
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.9607, acc: 0.5781
loss: 0.9184, acc: 0.6250
loss: 0.9510, acc: 0.5990
loss: 0.9621, acc: 0.5864
loss: 0.9529, acc: 0.5938
loss: 0.9584, acc: 0.5880
loss: 0.9497, acc: 0.5947
loss: 0.9551, acc: 0.5946
loss: 0.9572, acc: 0.5930
loss: 0.9540, acc: 0.5964
loss: 0.9560, acc: 0.5944
loss: 0.9573, acc: 0.5943
loss: 0.9500, acc: 0.6008
loss: 0.9525, acc: 0.5993
loss: 0.9513, acc: 0.6007
loss: 0.9495, acc: 0.6027
loss: 0.9486, acc: 0.6044
loss: 0.9473, acc: 0.6056
loss: 0.9494, acc: 0.6036
loss: 0.9501, acc: 0.6031
loss: 0.9521, acc: 0.6014
loss: 0.9529, acc: 0.6005
loss: 0.9528, acc: 0.6007
> val_acc: 0.6500, val_f1: 0.2626
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.9780, acc: 0.5703
loss: 0.9737, acc: 0.5799
loss: 0.9805, acc: 0.5737
loss: 0.9796, acc: 0.5740
loss: 0.9814, acc: 0.5729
loss: 0.9764, acc: 0.5776
loss: 0.9789, acc: 0.5754
loss: 0.9638, acc: 0.5881
loss: 0.9563, acc: 0.5916
loss: 0.9556, acc: 0.5931
loss: 0.9580, acc: 0.5909
loss: 0.9576, acc: 0.5922
loss: 0.9570, acc: 0.5903
loss: 0.9571, acc: 0.5906
loss: 0.9599, acc: 0.5878
loss: 0.9534, acc: 0.5941
loss: 0.9555, acc: 0.5923
loss: 0.9525, acc: 0.5941
loss: 0.9503, acc: 0.5951
loss: 0.9532, acc: 0.5944
loss: 0.9469, acc: 0.5986
loss: 0.9491, acc: 0.5960
> val_acc: 0.6500, val_f1: 0.2626
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.8658, acc: 0.6875
loss: 0.8987, acc: 0.6406
