n_trainable_params: 1010203, n_nontrainable_params: 347432
> training arguments:
>>> model_name: igcn_embed
>>> model_ver: 3
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adamax.Adamax'>
>>> initializer: <function xavier_uniform_ at 0x7f9b256eae18>
>>> learning_rate: 0.002
>>> momentum: 0.95
>>> dropout: 0.35
>>> l2reg: 5e-05
>>> num_epoch: 30
>>> batch_size: 32
>>> log_step: 5
>>> embed_dim: 136
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> embeddings: d
>>> max_seq_len: 300
>>> polarities_dim: 3
>>> hops: 3
>>> device: cpu
>>> seed: 0
>>> valset_ratio: 0
>>> num_layers: 1
>>> in_channels: 100
>>> out_channels: 1
>>> downbot: 20
>>> kernel_size: 3
>>> position_dim: 100
>>> gating: GTU
>>> stanford_pos_model: C:/NLP_Programs/stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger
>>> stanford_pos_jar: C:/NLP_Programs/stanford-postagger-2018-10-16/stanford-postagger.jar
>>> glove_path: ./embeddings/glove.840B.300d.txt
>>> embedding_matrix_path: gen_data/embeddings/100_laptop_domain_embedding_matrix.dat
>>> model_class: <class 'models.igcn.IGCN'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_raw_indices', 'aspect_indices', 'pos_indices', 'aspect_pos_indices', 'position_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.0936, acc: 0.3937
loss: 1.0631, acc: 0.4156
loss: 1.0229, acc: 0.4646
loss: 1.0117, acc: 0.4797
n_trainable_params: 1010203, n_nontrainable_params: 347432
> training arguments:
>>> model_name: igcn_embed
>>> model_ver: 3
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adamax.Adamax'>
>>> initializer: <function xavier_uniform_ at 0x7ff7ef436e18>
>>> learning_rate: 0.002
>>> momentum: 0.95
>>> dropout: 0.35
>>> l2reg: 5e-05
>>> num_epoch: 30
>>> batch_size: 32
>>> log_step: 5
>>> embed_dim: 136
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> embeddings: d
>>> max_seq_len: 300
>>> polarities_dim: 3
>>> hops: 3
>>> device: cpu
>>> seed: 0
>>> valset_ratio: 0
>>> num_layers: 1
>>> in_channels: 100
>>> out_channels: 1
>>> downbot: 20
>>> kernel_size: 3
>>> position_dim: 100
>>> gating: GLU
>>> stanford_pos_model: C:/NLP_Programs/stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger
>>> stanford_pos_jar: C:/NLP_Programs/stanford-postagger-2018-10-16/stanford-postagger.jar
>>> glove_path: ./embeddings/glove.840B.300d.txt
>>> embedding_matrix_path: gen_data/embeddings/100_laptop_domain_embedding_matrix.dat
>>> model_class: <class 'models.igcn.IGCN'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_raw_indices', 'aspect_indices', 'pos_indices', 'aspect_pos_indices', 'position_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 0.9773, acc: 0.5262
loss: 1.1307, acc: 0.3812
loss: 0.9700, acc: 0.5292
loss: 1.0795, acc: 0.4156
loss: 0.9589, acc: 0.5393
loss: 1.0314, acc: 0.4583
loss: 0.9428, acc: 0.5531
loss: 1.0157, acc: 0.4813
loss: 0.9424, acc: 0.5549
loss: 0.9761, acc: 0.5212
loss: 0.9344, acc: 0.5625
loss: 0.9650, acc: 0.5354
loss: 0.9262, acc: 0.5653
loss: 0.9517, acc: 0.5446
loss: 0.9143, acc: 0.5734
loss: 0.9338, acc: 0.5578
loss: 0.9058, acc: 0.5788
loss: 0.9323, acc: 0.5604
loss: 0.8943, acc: 0.5879
loss: 0.9224, acc: 0.5731
loss: 0.9133, acc: 0.5750
> val_acc: 0.6332, val_f1: 0.5087
> best_val_acc: 0.0000, best_val_f1: 0.0000
>> saved: state_dict/igcn_embed_laptop_val_acc0.6332
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.8998, acc: 0.5849
loss: 0.6213, acc: 0.7344
loss: 0.8897, acc: 0.5918
loss: 0.6905, acc: 0.7098
loss: 0.8774, acc: 0.6013
loss: 0.7050, acc: 0.6979
loss: 0.6984, acc: 0.7040
> val_acc: 0.6395, val_f1: 0.5143
> best_val_acc: 0.0000, best_val_f1: 0.0000
>> saved: state_dict/igcn_embed_laptop_val_acc0.6395
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.6953, acc: 0.7060
loss: 0.5505, acc: 0.7500
loss: 0.6845, acc: 0.7118
loss: 0.6380, acc: 0.7188
loss: 0.6794, acc: 0.7188
loss: 0.6539, acc: 0.7161
loss: 0.6754, acc: 0.7230
loss: 0.6477, acc: 0.7243
loss: 0.6810, acc: 0.7210
loss: 0.6475, acc: 0.7244
loss: 0.6747, acc: 0.7281
loss: 0.6356, acc: 0.7338
loss: 0.6746, acc: 0.7302
loss: 0.6302, acc: 0.7432
loss: 0.6825, acc: 0.7264
loss: 0.6243, acc: 0.7500
loss: 0.6760, acc: 0.7334
loss: 0.6316, acc: 0.7455
loss: 0.6765, acc: 0.7318
loss: 0.6254, acc: 0.7500
loss: 0.6735, acc: 0.7348
loss: 0.6243, acc: 0.7488
> val_acc: 0.6505, val_f1: 0.5472
> best_val_acc: 0.6332, best_val_f1: 0.5087
>> saved: state_dict/igcn_embed_laptop_val_acc0.6505
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.6324, acc: 0.7440
loss: 0.5572, acc: 0.8203
loss: 0.6262, acc: 0.7500
loss: 0.6108, acc: 0.7674
loss: 0.6261, acc: 0.7491
loss: 0.5932, acc: 0.7768
loss: 0.6227, acc: 0.7530
loss: 0.5863, acc: 0.7845
> val_acc: 0.6536, val_f1: 0.5493
> best_val_acc: 0.6395, best_val_f1: 0.5143
>> saved: state_dict/igcn_embed_laptop_val_acc0.6536
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.5763, acc: 0.7839
loss: 0.4904, acc: 0.8359
loss: 0.5731, acc: 0.7866
loss: 0.5459, acc: 0.7986
loss: 0.5791, acc: 0.7840
loss: 0.5283, acc: 0.8058
loss: 0.5739, acc: 0.7821
loss: 0.5215, acc: 0.8092
loss: 0.5704, acc: 0.7862
loss: 0.5118, acc: 0.8112
loss: 0.5601, acc: 0.7946
loss: 0.5068, acc: 0.8136
loss: 0.5616, acc: 0.7911
loss: 0.5154, acc: 0.8116
loss: 0.5578, acc: 0.7929
loss: 0.5099, acc: 0.8125
loss: 0.5596, acc: 0.7939
loss: 0.5083, acc: 0.8139
loss: 0.5606, acc: 0.7894
loss: 0.4980, acc: 0.8214
loss: 0.5026, acc: 0.8160
> val_acc: 0.6740, val_f1: 0.5816
> best_val_acc: 0.6505, best_val_f1: 0.5472
>> saved: state_dict/igcn_embed_laptop_val_acc0.674
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.4910, acc: 0.9062
loss: 0.4992, acc: 0.8157
loss: 0.4332, acc: 0.8542
loss: 0.5038, acc: 0.8140
loss: 0.4493, acc: 0.8466
loss: 0.5056, acc: 0.8116
loss: 0.4429, acc: 0.8516
loss: 0.4476, acc: 0.8542
> val_acc: 0.6912, val_f1: 0.6123
> best_val_acc: 0.6536, best_val_f1: 0.5493
>> saved: state_dict/igcn_embed_laptop_val_acc0.6912
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.4444, acc: 0.8498
loss: 0.3726, acc: 0.9375
loss: 0.4372, acc: 0.8538
loss: 0.3850, acc: 0.8698
loss: 0.4334, acc: 0.8559
loss: 0.3825, acc: 0.8722
loss: 0.4370, acc: 0.8498
loss: 0.3773, acc: 0.8867
loss: 0.4451, acc: 0.8458
loss: 0.3787, acc: 0.8884
loss: 0.4536, acc: 0.8395
loss: 0.3798, acc: 0.8834
loss: 0.4575, acc: 0.8382
loss: 0.3744, acc: 0.8831
loss: 0.4593, acc: 0.8376
loss: 0.3721, acc: 0.8837
loss: 0.4573, acc: 0.8362
loss: 0.3761, acc: 0.8796
loss: 0.4522, acc: 0.8389
loss: 0.3824, acc: 0.8736
loss: 0.3899, acc: 0.8676
> val_acc: 0.6771, val_f1: 0.5955
> best_val_acc: 0.6740, best_val_f1: 0.5816
>> saved: state_dict/igcn_embed_laptop_val_acc0.6771
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.3606, acc: 0.9167
loss: 0.3931, acc: 0.8650
loss: 0.3961, acc: 0.8750
loss: 0.3951, acc: 0.8617
loss: 0.3917, acc: 0.8918
loss: 0.3941, acc: 0.8603
loss: 0.3973, acc: 0.8976
loss: 0.3887, acc: 0.8649
loss: 0.3836, acc: 0.8981
> val_acc: 0.6771, val_f1: 0.6017
> best_val_acc: 0.6912, best_val_f1: 0.6123
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.3877, acc: 0.8895
loss: 0.3154, acc: 0.9375
loss: 0.3847, acc: 0.8930
loss: 0.3407, acc: 0.8906
loss: 0.3808, acc: 0.8947
loss: 0.3280, acc: 0.9062
loss: 0.3700, acc: 0.8983
loss: 0.3267, acc: 0.9115
loss: 0.3721, acc: 0.8913
loss: 0.3176, acc: 0.9103
loss: 0.3675, acc: 0.8903
loss: 0.3210, acc: 0.9107
loss: 0.3670, acc: 0.8917
loss: 0.3177, acc: 0.9138
loss: 0.3675, acc: 0.8894
loss: 0.3170, acc: 0.9137
loss: 0.3698, acc: 0.8869
loss: 0.3086, acc: 0.9186
loss: 0.3678, acc: 0.8870
loss: 0.3111, acc: 0.9108
> val_acc: 0.6803, val_f1: 0.6001
> best_val_acc: 0.6771, best_val_f1: 0.5955
>> saved: state_dict/igcn_embed_laptop_val_acc0.6803
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 0.3063, acc: 0.9127
loss: 0.3173, acc: 0.9125
loss: 0.3064, acc: 0.9122
loss: 0.3043, acc: 0.9281
loss: 0.3070, acc: 0.9102
loss: 0.3012, acc: 0.9292
loss: 0.3086, acc: 0.9062
loss: 0.2968, acc: 0.9344
loss: 0.3072, acc: 0.9081
loss: 0.2923, acc: 0.9325
loss: 0.2934, acc: 0.9271
> val_acc: 0.6959, val_f1: 0.6286
> best_val_acc: 0.6912, best_val_f1: 0.6123
>> saved: state_dict/igcn_embed_laptop_val_acc0.6959
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 0.2915, acc: 0.9250
loss: 0.2722, acc: 0.9187
loss: 0.2971, acc: 0.9227
loss: 0.2575, acc: 0.9281
loss: 0.3052, acc: 0.9181
loss: 0.2473, acc: 0.9354
loss: 0.3038, acc: 0.9194
loss: 0.2413, acc: 0.9422
loss: 0.3042, acc: 0.9170
loss: 0.2361, acc: 0.9437
loss: 0.3011, acc: 0.9198
loss: 0.2392, acc: 0.9396
loss: 0.2986, acc: 0.9197
loss: 0.2376, acc: 0.9411
loss: 0.2946, acc: 0.9201
loss: 0.2426, acc: 0.9383
loss: 0.2478, acc: 0.9368
> val_acc: 0.6740, val_f1: 0.5790
> best_val_acc: 0.6803, best_val_f1: 0.6001
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 0.2394, acc: 0.9688
loss: 0.2468, acc: 0.9369
loss: 0.2277, acc: 0.9732
loss: 0.2455, acc: 0.9358
loss: 0.2227, acc: 0.9714
loss: 0.2445, acc: 0.9380
loss: 0.2146, acc: 0.9706
loss: 0.2434, acc: 0.9385
loss: 0.2165, acc: 0.9673
loss: 0.2406, acc: 0.9402
loss: 0.2092, acc: 0.9722
loss: 0.2119, acc: 0.9697
> val_acc: 0.6928, val_f1: 0.6277
> best_val_acc: 0.6959, best_val_f1: 0.6286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 0.1920, acc: 0.9688
loss: 0.2108, acc: 0.9696
loss: 0.1839, acc: 0.9732
loss: 0.2134, acc: 0.9643
loss: 0.1810, acc: 0.9714
loss: 0.2151, acc: 0.9621
loss: 0.1742, acc: 0.9724
loss: 0.2182, acc: 0.9585
loss: 0.1771, acc: 0.9730
loss: 0.2185, acc: 0.9600
loss: 0.1703, acc: 0.9757
loss: 0.2182, acc: 0.9587
loss: 0.1706, acc: 0.9717
loss: 0.2203, acc: 0.9576
loss: 0.1709, acc: 0.9696
loss: 0.2254, acc: 0.9536
loss: 0.1707, acc: 0.9710
> val_acc: 0.6599, val_f1: 0.5674
> best_val_acc: 0.6803, best_val_f1: 0.6001
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
loss: 0.1706, acc: 0.9707
loss: 0.1584, acc: 0.9766
loss: 0.1722, acc: 0.9675
loss: 0.1690, acc: 0.9653
loss: 0.1714, acc: 0.9682
loss: 0.1703, acc: 0.9643
loss: 0.1715, acc: 0.9677
loss: 0.1683, acc: 0.9671
loss: 0.1721, acc: 0.9660
loss: 0.1661, acc: 0.9714
loss: 0.1770, acc: 0.9605
loss: 0.1658, acc: 0.9741
loss: 0.1683, acc: 0.9733
> val_acc: 0.6740, val_f1: 0.5872
> best_val_acc: 0.6959, best_val_f1: 0.6286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
loss: 0.1685, acc: 0.9712
loss: 0.1225, acc: 0.9766
loss: 0.1676, acc: 0.9716
loss: 0.1321, acc: 0.9792
loss: 0.1711, acc: 0.9694
loss: 0.1292, acc: 0.9844
loss: 0.1703, acc: 0.9705
loss: 0.1260, acc: 0.9836
loss: 0.1692, acc: 0.9725
loss: 0.1255, acc: 0.9844
loss: 0.1705, acc: 0.9722
loss: 0.1249, acc: 0.9828
loss: 0.1677, acc: 0.9728
loss: 0.1284, acc: 0.9825
loss: 0.1298, acc: 0.9824
> val_acc: 0.6928, val_f1: 0.6243
> best_val_acc: 0.6803, best_val_f1: 0.6001
>> saved: state_dict/igcn_embed_laptop_val_acc0.6928
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
loss: 0.1186, acc: 1.0000
loss: 0.1299, acc: 0.9822
loss: 0.1142, acc: 0.9896
loss: 0.1315, acc: 0.9821
loss: 0.1154, acc: 0.9943
loss: 0.1310, acc: 0.9832
loss: 0.1131, acc: 0.9922
loss: 0.1306, acc: 0.9841
loss: 0.1176, acc: 0.9911
loss: 0.1319, acc: 0.9834
loss: 0.1164, acc: 0.9916
loss: 0.1298, acc: 0.9837
loss: 0.1200, acc: 0.9909
loss: 0.1230, acc: 0.9896
> val_acc: 0.6787, val_f1: 0.5988
> best_val_acc: 0.6959, best_val_f1: 0.6286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
loss: 0.0980, acc: 1.0000
loss: 0.1243, acc: 0.9870
loss: 0.0986, acc: 0.9844
loss: 0.1235, acc: 0.9871
loss: 0.0954, acc: 0.9915
loss: 0.1252, acc: 0.9865
loss: 0.0929, acc: 0.9902
loss: 0.1283, acc: 0.9866
loss: 0.0950, acc: 0.9896
loss: 0.1279, acc: 0.9862
loss: 0.1278, acc: 0.9858
loss: 0.0943, acc: 0.9892
loss: 0.1280, acc: 0.9855
loss: 0.0959, acc: 0.9879
loss: 0.0986, acc: 0.9878
> val_acc: 0.6677, val_f1: 0.5769
> best_val_acc: 0.6928, best_val_f1: 0.6243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
loss: 0.0978, acc: 0.9893
loss: 0.1009, acc: 0.9896
loss: 0.0980, acc: 0.9905
loss: 0.1006, acc: 0.9961
loss: 0.0978, acc: 0.9902
loss: 0.0974, acc: 0.9952
loss: 0.1015, acc: 0.9883
loss: 0.0886, acc: 0.9965
loss: 0.1007, acc: 0.9882
loss: 0.0903, acc: 0.9946
loss: 0.1002, acc: 0.9877
loss: 0.0919, acc: 0.9955
loss: 0.1007, acc: 0.9872
loss: 0.0922, acc: 0.9962
loss: 0.0913, acc: 0.9942
> val_acc: 0.6818, val_f1: 0.5962
> best_val_acc: 0.6959, best_val_f1: 0.6286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
loss: 0.0800, acc: 0.9792
loss: 0.0913, acc: 0.9949
loss: 0.0792, acc: 0.9883
loss: 0.0915, acc: 0.9948
loss: 0.0917, acc: 0.9935
loss: 0.0776, acc: 0.9904
loss: 0.0916, acc: 0.9935
loss: 0.0725, acc: 0.9931
loss: 0.0926, acc: 0.9936
loss: 0.0703, acc: 0.9946
loss: 0.0922, acc: 0.9931
loss: 0.0723, acc: 0.9955
loss: 0.0935, acc: 0.9931
loss: 0.0729, acc: 0.9962
loss: 0.0736, acc: 0.9959
> val_acc: 0.6755, val_f1: 0.5949
> best_val_acc: 0.6928, best_val_f1: 0.6243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 10
loss: 0.0732, acc: 0.9964
loss: 0.0716, acc: 1.0000
loss: 0.0727, acc: 0.9967
loss: 0.0703, acc: 1.0000
loss: 0.0699, acc: 0.9979
loss: 0.0731, acc: 0.9965
loss: 0.0669, acc: 0.9984
loss: 0.0738, acc: 0.9962
loss: 0.0667, acc: 0.9988
loss: 0.0747, acc: 0.9965
loss: 0.0664, acc: 0.9990
loss: 0.0748, acc: 0.9963
loss: 0.0673, acc: 0.9991
loss: 0.0758, acc: 0.9957
loss: 0.0684, acc: 0.9977
> val_acc: 0.6959, val_f1: 0.6248
> best_val_acc: 0.6959, best_val_f1: 0.6286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 10
loss: 0.0674, acc: 0.9979
loss: 0.0663, acc: 1.0000
loss: 0.0670, acc: 0.9975
loss: 0.0664, acc: 1.0000
loss: 0.0674, acc: 0.9977
loss: 0.0643, acc: 1.0000
loss: 0.0676, acc: 0.9979
loss: 0.0609, acc: 1.0000
loss: 0.0671, acc: 0.9981
loss: 0.0587, acc: 1.0000
loss: 0.0682, acc: 0.9973
loss: 0.0569, acc: 1.0000
loss: 0.0573, acc: 1.0000
> val_acc: 0.6708, val_f1: 0.5851
> best_val_acc: 0.6928, best_val_f1: 0.6243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 11
loss: 0.0522, acc: 1.0000
loss: 0.0568, acc: 1.0000
loss: 0.0492, acc: 1.0000
loss: 0.0567, acc: 0.9986
loss: 0.0483, acc: 1.0000
loss: 0.0562, acc: 0.9981
loss: 0.0497, acc: 0.9982
loss: 0.0564, acc: 0.9983
loss: 0.0500, acc: 0.9986
loss: 0.0561, acc: 0.9984
loss: 0.0491, acc: 0.9988
loss: 0.0562, acc: 0.9976
loss: 0.0494, acc: 0.9980
loss: 0.0572, acc: 0.9973
loss: 0.0501, acc: 0.9975
loss: 0.0498, acc: 0.9978
> val_acc: 0.6850, val_f1: 0.6037
> best_val_acc: 0.6959, best_val_f1: 0.6286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 11
loss: 0.0499, acc: 0.9980
loss: 0.0403, acc: 1.0000
loss: 0.0508, acc: 0.9982
loss: 0.0406, acc: 1.0000
loss: 0.0506, acc: 0.9984
loss: 0.0390, acc: 1.0000
loss: 0.0515, acc: 0.9985
loss: 0.0425, acc: 1.0000
loss: 0.0527, acc: 0.9981
loss: 0.0434, acc: 1.0000
loss: 0.0528, acc: 0.9983
loss: 0.0426, acc: 1.0000
> val_acc: 0.6897, val_f1: 0.6175
> best_val_acc: 0.6928, best_val_f1: 0.6243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 12
loss: 0.0426, acc: 1.0000
loss: 0.0429, acc: 1.0000
loss: 0.0434, acc: 1.0000
loss: 0.0402, acc: 1.0000
loss: 0.0426, acc: 1.0000
loss: 0.0420, acc: 1.0000
loss: 0.0426, acc: 1.0000
loss: 0.0403, acc: 1.0000
loss: 0.0436, acc: 1.0000
loss: 0.0397, acc: 1.0000
loss: 0.0435, acc: 1.0000
loss: 0.0386, acc: 1.0000
loss: 0.0442, acc: 0.9995
loss: 0.0395, acc: 0.9991
loss: 0.0458, acc: 0.9986
loss: 0.0395, acc: 0.9992
loss: 0.0457, acc: 0.9987
loss: 0.0398, acc: 0.9993
> val_acc: 0.6975, val_f1: 0.6303
> best_val_acc: 0.6959, best_val_f1: 0.6286
>> saved: state_dict/igcn_embed_laptop_val_acc0.6975
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 12
loss: 0.0399, acc: 0.9987
loss: 0.0395, acc: 1.0000
loss: 0.0398, acc: 0.9988
loss: 0.0355, acc: 1.0000
loss: 0.0396, acc: 0.9989
loss: 0.0370, acc: 1.0000
loss: 0.0393, acc: 0.9990
loss: 0.0360, acc: 1.0000
loss: 0.0401, acc: 0.9991
loss: 0.0343, acc: 1.0000
loss: 0.0343, acc: 1.0000
> val_acc: 0.6771, val_f1: 0.5927
> best_val_acc: 0.6928, best_val_f1: 0.6243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 13
loss: 0.0248, acc: 1.0000
loss: 0.0349, acc: 0.9991
loss: 0.0394, acc: 1.0000
loss: 0.0353, acc: 0.9992
loss: 0.0345, acc: 1.0000
loss: 0.0355, acc: 0.9986
loss: 0.0334, acc: 1.0000
loss: 0.0357, acc: 0.9981
loss: 0.0315, acc: 1.0000
loss: 0.0316, acc: 1.0000
loss: 0.0357, acc: 0.9983
loss: 0.0308, acc: 1.0000
loss: 0.0357, acc: 0.9984
loss: 0.0314, acc: 1.0000
loss: 0.0354, acc: 0.9985
loss: 0.0305, acc: 1.0000
loss: 0.0361, acc: 0.9982
loss: 0.0311, acc: 1.0000
loss: 0.0314, acc: 1.0000
> val_acc: 0.6787, val_f1: 0.5962
> best_val_acc: 0.6975, best_val_f1: 0.6303
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 13
loss: 0.0255, acc: 1.0000
loss: 0.0316, acc: 1.0000
loss: 0.0301, acc: 1.0000
loss: 0.0315, acc: 1.0000
loss: 0.0294, acc: 1.0000
loss: 0.0315, acc: 1.0000
loss: 0.0289, acc: 1.0000
loss: 0.0315, acc: 1.0000
loss: 0.0294, acc: 1.0000
loss: 0.0294, acc: 1.0000
> val_acc: 0.6865, val_f1: 0.6164
> best_val_acc: 0.6928, best_val_f1: 0.6243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 14
loss: 0.0267, acc: 1.0000
loss: 0.0286, acc: 1.0000
loss: 0.0243, acc: 1.0000
loss: 0.0295, acc: 1.0000
loss: 0.0220, acc: 1.0000
loss: 0.0290, acc: 1.0000
loss: 0.0247, acc: 0.9983
loss: 0.0295, acc: 0.9993
loss: 0.0238, acc: 0.9986
loss: 0.0300, acc: 0.9994
loss: 0.0247, acc: 0.9989
loss: 0.0302, acc: 0.9994
loss: 0.0251, acc: 0.9991
loss: 0.0305, acc: 0.9990
loss: 0.0263, acc: 0.9984
loss: 0.0311, acc: 0.9986
loss: 0.0264, acc: 0.9985
loss: 0.0315, acc: 0.9987
loss: 0.0263, acc: 0.9987
loss: 0.0261, acc: 0.9988
> val_acc: 0.6693, val_f1: 0.6080
> best_val_acc: 0.6975, best_val_f1: 0.6303
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 14
loss: 0.0375, acc: 0.9896
loss: 0.0260, acc: 0.9989
loss: 0.0302, acc: 0.9961
loss: 0.0258, acc: 0.9990
loss: 0.0253, acc: 0.9976
loss: 0.0256, acc: 0.9991
loss: 0.0289, acc: 0.9965
loss: 0.0255, acc: 0.9991
loss: 0.0275, acc: 0.9973
> val_acc: 0.6865, val_f1: 0.6143
> best_val_acc: 0.6928, best_val_f1: 0.6243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 15
loss: 0.0277, acc: 0.9978
loss: 0.0172, acc: 1.0000
loss: 0.0280, acc: 0.9981
loss: 0.0174, acc: 1.0000
loss: 0.0285, acc: 0.9975
loss: 0.0175, acc: 1.0000
loss: 0.0289, acc: 0.9978
loss: 0.0175, acc: 1.0000
loss: 0.0284, acc: 0.9980
loss: 0.0178, acc: 1.0000
loss: 0.0285, acc: 0.9982
loss: 0.0176, acc: 1.0000
loss: 0.0283, acc: 0.9984
loss: 0.0176, acc: 1.0000
loss: 0.0276, acc: 0.9985
loss: 0.0183, acc: 1.0000
