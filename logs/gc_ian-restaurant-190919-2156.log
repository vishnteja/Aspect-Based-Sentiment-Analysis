cuda memory allocated: 12162048
n_trainable_params: 1714503, n_nontrainable_params: 1323600
> training arguments:
>>> model_name: gc_ian
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adagrad.Adagrad'>
>>> initializer: <function xavier_uniform_ at 0x0000019561BD7620>
>>> learning_rate: 0.01
>>> momentum: 0.95
>>> dropout: 0.2
>>> l2reg: 5e-05
>>> num_epoch: 30
>>> batch_size: 32
>>> log_step: 5
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> device: cuda
>>> seed: 10
>>> valset_ratio: 0
>>> num_layers: 1
>>> in_channels: 100
>>> out_channels: 1
>>> downbot: 10
>>> kernel_size: 3
>>> glove_path: ./glove/glove.840B.300d.txt
>>> model_class: <class 'models.gc_ian.GC_IAN'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_raw_indices', 'aspect_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 8.1876, acc: 0.4125
loss: 4.7864, acc: 0.4469
loss: 3.5990, acc: 0.4771
loss: 2.9542, acc: 0.4922
loss: 2.8093, acc: 0.4913
loss: 2.5182, acc: 0.4979
loss: 2.2912, acc: 0.5125
loss: 2.2056, acc: 0.5172
loss: 2.1764, acc: 0.5014
loss: 2.0626, acc: 0.5119
loss: 1.9657, acc: 0.5193
loss: 1.8749, acc: 0.5307
loss: 1.8134, acc: 0.5298
loss: 1.7508, acc: 0.5348
loss: 1.6960, acc: 0.5387
loss: 1.6497, acc: 0.5422
loss: 1.6064, acc: 0.5467
loss: 1.5696, acc: 0.5490
loss: 1.5381, acc: 0.5510
loss: 1.5060, acc: 0.5537
loss: 1.4803, acc: 0.5545
loss: 1.4565, acc: 0.5563
> val_acc: 0.6500, val_f1: 0.2626
>> saved: state_dict/gc_ian_restaurant_val_acc0.65
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 1.1004, acc: 0.4375
loss: 1.7866, acc: 0.4420
loss: 1.3925, acc: 0.5156
loss: 1.2331, acc: 0.5460
loss: 1.1688, acc: 0.5554
loss: 1.1144, acc: 0.5660
loss: 1.0779, acc: 0.5762
loss: 1.0447, acc: 0.5819
loss: 1.0220, acc: 0.5878
loss: 1.0079, acc: 0.5904
loss: 1.0037, acc: 0.5841
loss: 0.9892, acc: 0.5888
loss: 0.9822, acc: 0.5867
loss: 0.9754, acc: 0.5905
loss: 0.9624, acc: 0.5951
loss: 0.9574, acc: 0.5938
loss: 0.9573, acc: 0.5922
loss: 0.9545, acc: 0.5927
loss: 0.9506, acc: 0.5924
loss: 0.9492, acc: 0.5950
loss: 0.9502, acc: 0.5944
loss: 0.9499, acc: 0.5935
loss: 0.9476, acc: 0.5957
> val_acc: 0.5991, val_f1: 0.3610
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.8474, acc: 0.6562
loss: 0.9040, acc: 0.5972
loss: 0.8910, acc: 0.5982
loss: 0.9237, acc: 0.5740
loss: 0.9168, acc: 0.5846
loss: 0.9220, acc: 0.5808
loss: 0.9077, acc: 0.5882
loss: 0.9040, acc: 0.5897
loss: 0.8934, acc: 0.5895
loss: 0.8951, acc: 0.5944
loss: 0.8883, acc: 0.6024
loss: 0.8867, acc: 0.6043
loss: 0.8800, acc: 0.6099
loss: 0.8874, acc: 0.6069
loss: 0.8967, acc: 0.6026
loss: 0.8985, acc: 0.6021
loss: 0.8992, acc: 0.5978
loss: 0.9087, acc: 0.5969
loss: 0.9169, acc: 0.5934
loss: 0.9253, acc: 0.5906
loss: 0.9211, acc: 0.5947
loss: 0.9240, acc: 0.5943
> val_acc: 0.6464, val_f1: 0.3811
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.7781, acc: 0.6875
loss: 0.8531, acc: 0.6198
loss: 0.8349, acc: 0.6165
loss: 0.8534, acc: 0.6035
loss: 0.8475, acc: 0.6101
loss: 0.8459, acc: 0.6166
loss: 0.8815, acc: 0.6018
loss: 0.8817, acc: 0.6007
loss: 0.8721, acc: 0.5991
