cuda memory allocated: 7165952
n_trainable_params: 1439803, n_nontrainable_params: 347432
> training arguments:
>>> model_name: igcn_embed
>>> model_ver: 3
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adamax.Adamax'>
>>> initializer: <function xavier_uniform_ at 0x0000025A95154D90>
>>> learning_rate: 0.02
>>> momentum: 0.95
>>> dropout: 0.5
>>> l2reg: 5e-05
>>> num_epoch: 30
>>> batch_size: 32
>>> log_step: 5
>>> embed_dim: 136
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> embeddings: d
>>> max_seq_len: 180
>>> polarities_dim: 3
>>> hops: 3
>>> device: cuda
>>> seed: 0
>>> valset_ratio: 0
>>> num_layers: 1
>>> in_channels: 100
>>> out_channels: 1
>>> downbot: 20
>>> kernel_size: 3
>>> position_dim: 100
>>> gating: GTU
>>> stanford_pos_model: C:/NLP_Programs/stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger
>>> stanford_pos_jar: C:/NLP_Programs/stanford-postagger-2018-10-16/stanford-postagger.jar
>>> glove_path: ./embeddings/glove.840B.300d.txt
>>> embedding_matrix_path: gen_data/embeddings/100_laptop_domain_embedding_matrix.dat
>>> model_class: <class 'models.igcn.IGCN'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_raw_indices', 'aspect_indices', 'pos_indices', 'aspect_pos_indices', 'position_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 3.3527, acc: 0.3187
loss: 2.3514, acc: 0.2969
loss: 1.9366, acc: 0.3333
loss: 1.7523, acc: 0.3469
loss: 1.6113, acc: 0.3688
loss: 1.5253, acc: 0.3802
loss: 1.4550, acc: 0.3929
loss: 1.3985, acc: 0.4109
loss: 1.3469, acc: 0.4306
loss: 1.3118, acc: 0.4394
loss: 1.2689, acc: 0.4642
loss: 1.2406, acc: 0.4698
loss: 1.2108, acc: 0.4822
loss: 1.1839, acc: 0.4964
> val_acc: 0.6019, val_f1: 0.4398
> best_val_acc: 0.0000, best_val_f1: 0.0000
>> saved: state_dict/igcn_embed_laptop_val_acc0.6019
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7985, acc: 0.6094
loss: 0.7436, acc: 0.6786
loss: 0.7593, acc: 0.6615
loss: 0.7656, acc: 0.6544
loss: 0.7885, acc: 0.6520
loss: 0.7811, acc: 0.6562
loss: 0.7945, acc: 0.6523
loss: 0.7797, acc: 0.6596
loss: 0.7649, acc: 0.6652
loss: 0.7688, acc: 0.6629
loss: 0.7671, acc: 0.6641
loss: 0.7725, acc: 0.6617
loss: 0.7691, acc: 0.6658
loss: 0.7696, acc: 0.6660
loss: 0.7726, acc: 0.6619
> val_acc: 0.6771, val_f1: 0.5692
> best_val_acc: 0.6019, best_val_f1: 0.4398
>> saved: state_dict/igcn_embed_laptop_val_acc0.6771
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.7303, acc: 0.7266
loss: 0.7105, acc: 0.6979
loss: 0.6957, acc: 0.7098
loss: 0.7006, acc: 0.7089
loss: 0.6995, acc: 0.7122
loss: 0.6893, acc: 0.7112
loss: 0.6843, acc: 0.7169
loss: 0.6797, acc: 0.7196
loss: 0.6771, acc: 0.7166
loss: 0.6818, acc: 0.7149
loss: 0.6740, acc: 0.7176
loss: 0.6677, acc: 0.7193
loss: 0.6604, acc: 0.7222
loss: 0.6592, acc: 0.7215
> val_acc: 0.6991, val_f1: 0.6258
> best_val_acc: 0.6771, best_val_f1: 0.5692
>> saved: state_dict/igcn_embed_laptop_val_acc0.6991
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.5706, acc: 0.7812
loss: 0.5927, acc: 0.7760
loss: 0.6103, acc: 0.7642
loss: 0.6104, acc: 0.7578
loss: 0.6300, acc: 0.7426
loss: 0.6209, acc: 0.7476
loss: 0.6112, acc: 0.7530
loss: 0.6118, acc: 0.7491
